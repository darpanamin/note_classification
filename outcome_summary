
Overview:

Data Prep
-Used the HP note audit excel to identify notes to gather from Clarity.  
-Moved a raw dump of the notes data to HDFS.  
-Created Spark dataframes to create a final dataframe.  Used sparksql to merge the lines of note text into one column.
-Ended up with an inventory of 206 notes.  With more 'Yes = note audited to complete" vs No's.  

Training
-Created a training dataset with 115 notes.  100 = Y 15 = N
-Used Scikit Learn to vectorize and classify
-For vectorizing the data used DTMs.
-For vectorizing the data looked at 4 approaches
  TFID
  TFID with parameters to eliminate outlier tokens and common english stop words
  Count Vec
  Count Vec with a custom vocab of 25 words created by analyzing the 'good HP notes'
-For ML classifiers
   Naive Bayes (Multinomial)
   Naive Bayes (Bernoulli)
   SVM with SGD (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)
   SVM with SGD with penalty = elasticnet
   Neural Networks w/ SGD using various settings for hidden layer and number of iterations
   
-Created pipelines with to combine the vectorizers and classifiers
-Saved trained models

Testing
- Created/Used the following test datasets
  Training Dataset as Test Dataset
  EX : All notes not part of training data
  EQ:  Random samples from the EX dataset where Yes/No breakdown is 50/50
  Random: random samples from the entire set of notes data available
- Chose SVM with SGD penalty = elasticnet because it showed the best results.  
- Using CountVec with custom vocub seemed to do the best to improve sensitivity of the No's.  


Terms:
TFID = Term Frequency Inverse Document Frequency
SGD = Stochastic Gradient Descent
Count Vec = Sparse representation of token counts for each note


************************************************************************************
Option 1:
TFID / SGD  (TFID with parameters to remove outliers)
************************************************************************************

EX Test (91 size)  All records distinct from training set

                precision   recall  f1-score   support

          N       1.00      0.52      0.69        23
          Y       0.86      1.00      0.93        68

avg / total       0.90      0.88      0.86        91


EQ Test (30 size)  Subset of EX set with 50/50 split of Y and N

             precision    recall  f1-score   support

          N       1.00      0.80      0.89        15
          Y       0.83      1.00      0.91        15

avg / total       0.92      0.90      0.90        30


Random Test (46)  could include records from training data

             precision    recall  f1-score   support

          N       1.00      0.83      0.91         6
          Y       0.98      1.00      0.99        40

avg / total       0.98      0.98      0.98        46

******************************************************************************************************
Option 2
Count Vec with custom vocab / SGD
******************************************************************************************************

EX Test (91 size)


             precision    recall  f1-score   support

          N       0.62      0.65      0.64        23
          Y       0.88      0.87      0.87        68

avg / total       0.82      0.81      0.81        91



EQ Test (30 size)

             precision    recall  f1-score   support

          N       0.86      0.80      0.83        15
          Y       0.81      0.87      0.84        15

avg / total       0.83      0.83      0.83        30

Random Test (46) could include records from training data

             precision    recall  f1-score   support

          N       0.36      0.67      0.47         6
          Y       0.94      0.82      0.88        40

avg / total       0.87      0.80      0.83        46

******************************************************************************************************
Option 3
Count Vec with custom vocab / Neural Networks (solver =  SGD , hidden layer = 28 neuron (single layer), 500 iterations)
******************************************************************************************************

EX Test (91 size)

             precision    recall  f1-score   support

          N       1.00      0.65      0.79        23
          Y       0.89      1.00      0.94        68

avg / total       0.92      0.91      0.91        91


EQ Test (30 size)

             precision    recall  f1-score   support

          N       0.92      0.80      0.86        15
          Y       0.82      0.93      0.87        15

avg / total       0.87      0.87      0.87        30

Random Test (53) could include records from training data

             precision    recall  f1-score   support

          N       1.00      0.73      0.84        11
          Y       0.93      1.00      0.97        42

avg / total       0.95      0.94      0.94        53
